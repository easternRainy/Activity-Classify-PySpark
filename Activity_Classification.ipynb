{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classification from Smartphone and Smartwatch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Goal Description\n",
    "In this project, we use [WISDM Smartphone and Smartwatch Activity and Biometrics Dataset Data Set](https://archive.ics.uci.edu/ml/datasets/WISDM+Smartphone+and+Smartwatch+Activity+and+Biometrics+Dataset+) to build an acitivity classifier based on sensor data. There are 51 test subjects whose subject-ids are from 1600-1650. These test subjects wears smart phone and smart watch to perform 18 different kinds of activities (coded form A to S). \n",
    "\n",
    "- A: Walking \n",
    "- B: Jogging\n",
    "- C: Stairs\n",
    "- D: Sitting\n",
    "- E: Standing\n",
    "- F: Typing\n",
    "- G: Brushing Teeth\n",
    "- H: Eating Soup\n",
    "- I: Eating Chips\n",
    "- J: Eating Pasta\n",
    "- K: Drinking from Cup\n",
    "- L: Eating Sandwich\n",
    "- M: Kicking Soccer Ball\n",
    "- O: Palying Catch w/Tennis Ball\n",
    "- P: Dribbling Basketball\n",
    "- Q: Writing\n",
    "- R: Clapping\n",
    "- S: Folding Clothes\n",
    "\n",
    "Each device has two kinds of sensors: accelerometer and gyroscope. During each activity, theses sensors collect the following data:\n",
    "- x: represents the sensor reading (accelerometer or gyroscope) for the x dimension \n",
    "- y: represents the sensor reading (accelerometer or gyroscope) for the y dimension \n",
    "- z: represents the sensor reading (accelerometer or gyroscope) for the z dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisdm_files = \"WISDM/*/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import asc, desc\n",
    "from pyspark.sql.functions import avg, round\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "from utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.config('spark.driver.extraClassPath', 'postgresql-42.2.18.jar') \\\n",
    "                         .config(\"spark.executor.memory\", \"16g\") \\\n",
    "                         .config(\"spark.driver.memory\", \"16g\") \\\n",
    "                         .config(\"spark.executor.cores\", 8) \\\n",
    "                         .config('spark.executor.instances', 4).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.getOrCreate()\n",
    "sc = ss.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_rdd = sc.wholeTextFiles(wisdm_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"subject_id\", IntegerType(), False),\n",
    "    StructField(\"sensor\", StringType(), False),\n",
    "    StructField(\"device\", StringType(), False),\n",
    "    StructField(\"activity_code\", StringType(), False),\n",
    "    StructField(\"timestamp\", LongType(), False),\n",
    "    StructField(\"x\", FloatType(), False),\n",
    "    StructField(\"y\", FloatType(), False),\n",
    "    StructField(\"z\", FloatType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activity = create_activity_df(ss, files_rdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+-------------+---------------+------------+------------+------------+\n",
      "|subject_id|sensor|device|activity_code|      timestamp|           x|           y|           z|\n",
      "+----------+------+------+-------------+---------------+------------+------------+------------+\n",
      "|      1613|  gyro| phone|            A|178468071944614|-0.020240024|-0.004261058|-0.023435818|\n",
      "|      1613|  gyro| phone|            A|178468104194617|  -2.5750105|  0.18109496|   1.3864417|\n",
      "|      1613|  gyro| phone|            A|178468142811857|  -1.5739282|   0.6668556|    1.320928|\n",
      "|      1613|  gyro| phone|            A|178468183987271|  -1.5041534|   1.7973675|    0.824781|\n",
      "|      1613|  gyro| phone|            A|178468225406856| -0.50786483|   1.6002935|  0.45833004|\n",
      "+----------+------+------+-------------+---------------+------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_activity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to check the number of items for each activity, sensor, and device. First, group data by \"activity_code\", \"device\", and \"sensor\". Count the number of data items in each group. As the result shows, the data is well balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_balance = df_activity.groupBy(\"activity_code\", \"device\", \"sensor\") \\\n",
    "                              .count().alias(\"count\") \\\n",
    "                              .orderBy(\"activity_code\", \"device\", \"sensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+------+------+\n",
      "|activity_code|device|sensor| count|\n",
      "+-------------+------+------+------+\n",
      "|            A| phone| accel|279817|\n",
      "|            A| phone|  gyro|203919|\n",
      "|            A| watch| accel|210495|\n",
      "|            A| watch|  gyro|192531|\n",
      "|            B| phone| accel|268409|\n",
      "|            B| phone|  gyro|200252|\n",
      "|            B| watch| accel|205787|\n",
      "|            B| watch|  gyro|187833|\n",
      "|            C| phone| accel|255645|\n",
      "|            C| phone|  gyro|197857|\n",
      "|            C| watch| accel|207312|\n",
      "|            C| watch|  gyro|180416|\n",
      "|            D| phone| accel|264592|\n",
      "|            D| phone|  gyro|202370|\n",
      "|            D| watch| accel|213018|\n",
      "|            D| watch|  gyro|195050|\n",
      "|            E| phone| accel|269604|\n",
      "|            E| phone|  gyro|202351|\n",
      "|            E| watch| accel|216529|\n",
      "|            E| watch|  gyro|194103|\n",
      "+-------------+------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_check_balance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separate data by sensor type: accelerometer and gyroscope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel = df_activity.filter(\"sensor == 'accel'\") \\\n",
    "                      .withColumnRenamed(\"x\", \"accel_x\") \\\n",
    "                      .withColumnRenamed(\"y\", \"accel_y\") \\\n",
    "                      .withColumnRenamed(\"z\", \"accel_z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gyro  = df_activity.filter(\"sensor == 'gyro'\") \\\n",
    "                      .withColumnRenamed(\"x\", \"gyro_x\") \\\n",
    "                      .withColumnRenamed(\"y\", \"gyro_y\") \\\n",
    "                      .withColumnRenamed(\"z\", \"gyro_z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Join both dataframes by the same activity code, device and timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join condition\n",
    "join_cond = (df_accel.activity_code == df_gyro.activity_code) & \\\n",
    "            (df_accel.device == df_gyro.device) & \\\n",
    "            (df_accel.timestamp == df_gyro.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both = df_accel.join(df_gyro, join_cond, 'inner') \\\n",
    "                  .select(\n",
    "    \n",
    "                      df_accel.activity_code,\n",
    "                      df_accel.subject_id,\n",
    "                      df_accel.device,\n",
    "                      df_accel.timestamp,\n",
    "                      df_accel.accel_x,\n",
    "                      df_accel.accel_y,\n",
    "                      df_accel.accel_z,\n",
    "                      df_gyro.gyro_x,\n",
    "                      df_gyro.gyro_y,\n",
    "                      df_gyro.gyro_z,\n",
    "                    \n",
    "                  ).distinct().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-------------+-------+-------+-------+------+------+------+\n",
      "|activity_code|subject_id|device|    timestamp|accel_x|accel_y|accel_z|gyro_x|gyro_y|gyro_z|\n",
      "+-------------+----------+------+-------------+-------+-------+-------+------+------+------+\n",
      "|            A|      1623| phone|2520873744873| -2.717| -2.945|  0.465| 0.656|-0.797|-0.462|\n",
      "|            A|      1623| phone|2525808428600|  4.735|-13.048| -1.625|-1.616| -0.51|-0.425|\n",
      "|            A|      1623| phone|2529887102917| -0.137| -9.755| -1.037| 1.076| 0.412| 0.555|\n",
      "|            A|      1623| phone|2541569242466|  2.737|-11.875| -1.139| 1.696| 1.246| 0.165|\n",
      "|            A|      1623| phone|2546604630192| -1.418| -3.727|  0.475|-0.962|-1.724|-0.561|\n",
      "+-------------+----------+------+-------------+-------+-------+-------+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_both.select([c for c in df_both.columns[:4]]+[round(c, 3).alias(c) for c in df_both.columns[4:]]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5901089"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_both.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For the same subject_id, activity_code and device, add lead_x_sensor column, which is x rows after the current row. This feature engineering is because we want to use the time series order to make classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"subject_id\", \"activity_code\", \"device\") \\\n",
    "          .orderBy(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_array = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "scaled_array = [col_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, window_size+1):\n",
    "    lead_array = []\n",
    "    for sensor in col_array:\n",
    "        df_both = df_both.withColumn(f\"lead_{i}_{sensor}\", lead(f\"{sensor}\", i).over(w))\n",
    "        lead_array.append(f\"lead_{i}_{sensor}\")\n",
    "    scaled_array.append(lead_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both = df_both.orderBy(\"subject_id\", \"activity_code\", \"device\", \"timestamp\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cols = [\"subject_id\", \"activity_code\", \"device\", \"timestamp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show the first 5 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------+---------------+-------+-------+-------+------+------+------+\n",
      "|subject_id|activity_code|device|      timestamp|accel_x|accel_y|accel_z|gyro_x|gyro_y|gyro_z|\n",
      "+----------+-------------+------+---------------+-------+-------+-------+------+------+------+\n",
      "|      1600|            A| phone|252207918580802| -4.333| 13.361| -0.719|-0.853| 0.297|  0.89|\n",
      "|      1600|            A| phone|252207968934806| -0.319| 13.318| -0.232|-0.875| 0.015| 0.162|\n",
      "|      1600|            A| phone|252208019288809|  1.566|  9.515| -0.018| -0.72| 0.388|-0.284|\n",
      "|      1600|            A| phone|252208069642813| -0.324|  5.263|  0.322|-0.572| 1.227|-0.242|\n",
      "|      1600|            A| phone|252208119996817| -1.812|  3.711|  1.374| -0.38| 1.203|-0.213|\n",
      "+----------+-------------+------+---------------+-------+-------+-------+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truncate_show(df_both, truncate_cols=scaled_array[0], selected_cols=base_cols+scaled_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------+-------------+-------------+-------------+\n",
      "|lead_1_accel_x|lead_1_accel_y|lead_1_accel_z|lead_1_gyro_x|lead_1_gyro_y|lead_1_gyro_z|\n",
      "+--------------+--------------+--------------+-------------+-------------+-------------+\n",
      "|        -0.319|        13.318|        -0.232|       -0.875|        0.015|        0.162|\n",
      "|         1.566|         9.515|        -0.018|        -0.72|        0.388|       -0.284|\n",
      "|        -0.324|         5.263|         0.322|       -0.572|        1.227|       -0.242|\n",
      "|        -1.812|         3.711|         1.374|        -0.38|        1.203|       -0.213|\n",
      "|        -1.134|         4.538|         2.298|       -0.226|        0.558|        0.124|\n",
      "+--------------+--------------+--------------+-------------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truncate_show(df_both, truncate_cols=scaled_array[1], selected_cols=scaled_array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------+-------------+-------------+-------------+\n",
      "|lead_5_accel_x|lead_5_accel_y|lead_5_accel_z|lead_5_gyro_x|lead_5_gyro_y|lead_5_gyro_z|\n",
      "+--------------+--------------+--------------+-------------+-------------+-------------+\n",
      "|        -1.134|         4.538|         2.298|       -0.226|        0.558|        0.124|\n",
      "|         0.093|         6.706|           1.9|        0.128|         0.38|        0.553|\n",
      "|        -1.036|        15.612|         2.642|       -0.514|         0.38|        0.332|\n",
      "|         0.752|         9.683|         3.001|        0.446|       -0.511|       -0.113|\n",
      "|        -0.497|        18.677|         0.937|       -1.357|       -0.435|       -0.455|\n",
      "+--------------+--------------+--------------+-------------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truncate_show(df_both, truncate_cols=scaled_array[5], selected_cols=scaled_array[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Convert \"device\" column to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = index_string_cols(df_both, ['device'])\n",
    "df_numeric = one_hot_encode_cols(df_numeric, ['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+---------------+-------+-------+-------+------+------+------+\n",
      "|subject_id|activity_code|       device|      timestamp|accel_x|accel_y|accel_z|gyro_x|gyro_y|gyro_z|\n",
      "+----------+-------------+-------------+---------------+-------+-------+-------+------+------+------+\n",
      "|      1600|            A|(2,[1],[1.0])|252207918580802| -4.333| 13.361| -0.719|-0.853| 0.297|  0.89|\n",
      "|      1600|            A|(2,[1],[1.0])|252207968934806| -0.319| 13.318| -0.232|-0.875| 0.015| 0.162|\n",
      "|      1600|            A|(2,[1],[1.0])|252208019288809|  1.566|  9.515| -0.018| -0.72| 0.388|-0.284|\n",
      "|      1600|            A|(2,[1],[1.0])|252208069642813| -0.324|  5.263|  0.322|-0.572| 1.227|-0.242|\n",
      "|      1600|            A|(2,[1],[1.0])|252208119996817| -1.812|  3.711|  1.374| -0.38| 1.203|-0.213|\n",
      "+----------+-------------+-------------+---------------+-------+-------+-------+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truncate_show(df_numeric, truncate_cols=scaled_array[0], selected_cols=base_cols+scaled_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Convert \"activity_code\" to string indexer for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = StringIndexer(inputCol=\"activity_code\", outputCol=\"label\")\n",
    "sm = si.fit(df_numeric)\n",
    "df_numeric = sm.transform(df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+---------------+-------+-------+-------+------+------+------+-----+\n",
      "|subject_id|activity_code|       device|      timestamp|accel_x|accel_y|accel_z|gyro_x|gyro_y|gyro_z|label|\n",
      "+----------+-------------+-------------+---------------+-------+-------+-------+------+------+------+-----+\n",
      "|      1600|            A|(2,[1],[1.0])|252207918580802| -4.333| 13.361| -0.719|-0.853| 0.297|  0.89| 14.0|\n",
      "|      1600|            A|(2,[1],[1.0])|252207968934806| -0.319| 13.318| -0.232|-0.875| 0.015| 0.162| 14.0|\n",
      "|      1600|            A|(2,[1],[1.0])|252208019288809|  1.566|  9.515| -0.018| -0.72| 0.388|-0.284| 14.0|\n",
      "|      1600|            A|(2,[1],[1.0])|252208069642813| -0.324|  5.263|  0.322|-0.572| 1.227|-0.242| 14.0|\n",
      "|      1600|            A|(2,[1],[1.0])|252208119996817| -1.812|  3.711|  1.374| -0.38| 1.203|-0.213| 14.0|\n",
      "+----------+-------------+-------------+---------------+-------+-------+-------+------+------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truncate_show(df_numeric, truncate_cols=scaled_array[0], selected_cols=base_cols+scaled_array[0]+['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_2_index = dict()\n",
    "index_2_code = dict()\n",
    "\n",
    "for i, code in enumerate(sm.labels):\n",
    "    code_2_index[code] = i\n",
    "    index_2_code[i] = code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is how the index corresponds to activity code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 0,\n",
       " 'Q': 1,\n",
       " 'E': 2,\n",
       " 'J': 3,\n",
       " 'K': 4,\n",
       " 'G': 5,\n",
       " 'S': 6,\n",
       " 'R': 7,\n",
       " 'L': 8,\n",
       " 'H': 9,\n",
       " 'I': 10,\n",
       " 'F': 11,\n",
       " 'C': 12,\n",
       " 'P': 13,\n",
       " 'A': 14,\n",
       " 'M': 15,\n",
       " 'B': 16,\n",
       " 'O': 17}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_2_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the data to easy the future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"TimeSeriesWISDM\"\n",
    "# sc.setSystemProperty('spark.executor.memory', '16g')\n",
    "# df_numeric.write.parquet(f\"{save_path}/TimeSeriesWISDM.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Combine accelerometer and gyroscope data using Vector Assembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=np.array(scaled_array).flatten(), outputCol=\"features\", handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assem = va.transform(df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------------------------------------------------------------------+-----+\n",
      "|       device|                                                                        features|label|\n",
      "+-------------+--------------------------------------------------------------------------------+-----+\n",
      "|(2,[1],[1.0])|[-4.3327789306640625,13.361190795898438,-0.7188720703125,-0.85321044921875,0....| 14.0|\n",
      "|(2,[1],[1.0])|[-0.3194427490234375,13.318359375,-0.232025146484375,-0.8751373291015625,0.01...| 14.0|\n",
      "|(2,[1],[1.0])|[1.5664520263671875,9.515274047851562,-0.0177764892578125,-0.7201690673828125...| 14.0|\n",
      "|(2,[1],[1.0])|[-0.3237457275390625,5.262664794921875,0.3223419189453125,-0.5716400146484375...| 14.0|\n",
      "|(2,[1],[1.0])|[-1.811676025390625,3.71051025390625,1.373931884765625,-0.3804931640625,1.202...| 14.0|\n",
      "+-------------+--------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_assem.select(\"device\", \"features\", \"label\").show(n=5, truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scale features using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\", withStd=True, withMean=True)\n",
    "sm = scaler.fit(df_assem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = sm.transform(df_assem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df_norm.orderBy(\"subject_id\", \"activity_code\", \"device\", \"timestamp\") \\\n",
    "                 .select(\"device\", \"features_scaled\", \"label\") \\\n",
    "                 .withColumnRenamed(\"features_scaled\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------------------------------------------------------------------+-----+\n",
      "|       device|                                                                        features|label|\n",
      "+-------------+--------------------------------------------------------------------------------+-----+\n",
      "|(2,[0],[1.0])|[0.6954400989779945,0.4530803375160773,0.9924294490408299,0.2544527515486165,...| 14.0|\n",
      "|(2,[0],[1.0])|[0.4289174398658605,0.447655521116998,0.8804437884527041,0.3097779563474296,-...| 14.0|\n",
      "|(2,[0],[1.0])|[0.3587603552569157,0.45346782388494133,0.8595033973287532,0.0681370469072560...| 14.0|\n",
      "|(2,[0],[1.0])|[0.5090969545718377,0.308547782053457,1.1890873072415338,0.042915269563367484...| 14.0|\n",
      "|(2,[0],[1.0])|[0.6471839540663571,0.5061660206953301,1.560551908737828,0.06976425981730071,...| 14.0|\n",
      "+-------------+--------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_norm.show(n=5, truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Combine features and device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=[\"features\", \"device\"], \n",
    "                     outputCol=\"scaled_features_device\", \n",
    "                     handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = va.transform(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df_norm.select(\"scaled_features_device\", \"label\") \\\n",
    "                .withColumnRenamed(\"scaled_features_device\", \"features\") \\\n",
    "                .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+-----+\n",
      "|                                                                                            features|label|\n",
      "+----------------------------------------------------------------------------------------------------+-----+\n",
      "|[0.6954400989779945,0.4530803375160773,0.9924294490408299,0.2544527515486165,-0.7838831647324762,...| 14.0|\n",
      "|[0.4289174398658605,0.447655521116998,0.8804437884527041,0.3097779563474296,-0.468374385712814,-0...| 14.0|\n",
      "|[0.3587603552569157,0.45346782388494133,0.8595033973287532,0.06813704690725604,-0.148703285592765...| 14.0|\n",
      "|[0.5090969545718377,0.308547782053457,1.1890873072415338,0.042915269563367484,0.21425661540024654...| 14.0|\n",
      "|[0.6471839540663571,0.5061660206953301,1.560551908737828,0.06976425981730071,0.5772165396830097,-...| 14.0|\n",
      "+----------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_norm.show(n=5, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"TimeSeriesWISDM\"\n",
    "df_norm.write.parquet(f\"{save_path}/norm_WISDM.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
